{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08402bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "#         metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        temperature_h,\n",
    "        temperature_e,\n",
    "        alpha_h,\n",
    "        alpha_e\n",
    "\n",
    "    ):\n",
    "\n",
    "        super().compile(optimizer=optimizer,metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha_h = alpha_h\n",
    "        self.alpha_e = alpha_e\n",
    "        self.temperature_h = temperature_h\n",
    "        self.temperature_e = temperature_e\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        x, [y_h,y_e] = data\n",
    "        print('x.shape',x.shape.as_list())\n",
    "        print('y_h.shape',y_h.shape.as_list())\n",
    "\n",
    "        teacher_prediction_h, teacher_prediction_e= self.teacher(x, training=False)\n",
    "        print('teacher_prediction_h.shape',teacher_prediction_h.shape.as_list())\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_prediction_h,student_prediction_e = self.student(x, training=True)\n",
    "            print('student_prediction_h.shape',student_prediction_h.shape.as_list())\n",
    "            # Compute losses\n",
    "            student_loss_h = self.student_loss_fn(y_h, student_prediction_h)\n",
    "            student_loss_e = self.student_loss_fn(y_e, student_prediction_e)\n",
    "#             student_loss= 0.5*(student_loss_h+student_loss_e)\n",
    "            \n",
    "\n",
    "            # The magnitudes of the gradients produced by the soft targets scale\n",
    "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
    "\n",
    "            distillation_loss_h = (\n",
    "                self.distillation_loss_fn(\n",
    "                    tf.nn.softmax(teacher_prediction_h / self.temperature_h, axis=-1),\n",
    "                    tf.nn.softmax(student_prediction_h / self.temperature_h, axis=-1),\n",
    "                )\n",
    "                * self.temperature_h**2\n",
    "            )\n",
    "            \n",
    "            distillation_loss_e = (\n",
    "                self.distillation_loss_fn(\n",
    "                    tf.nn.softmax(teacher_prediction_e / self.temperature_e, axis=-1),\n",
    "                    tf.nn.softmax(student_prediction_e / self.temperature_e, axis=-1),\n",
    "                )\n",
    "                * self.temperature_e**2\n",
    "            )\n",
    "\n",
    "            loss_h = self.alpha_h * student_loss_h + (1 - self.alpha_h) * distillation_loss_h\n",
    "            loss_e = self.alpha_e * student_loss_e + (1 - self.alpha_e) * distillation_loss_e\n",
    "            loss=0.5*loss_h+0.5*loss_e\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "\n",
    "\n",
    "        self.compiled_metrics.update_state([y_h,y_e], [student_prediction_h,student_prediction_e])\n",
    "\n",
    "    \n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "        results.update({\"loss\": loss})\n",
    "        return results      \n",
    "\n",
    "\n",
    "    def predict(self,db_test_x,batchz=None,verbose=True):\n",
    "     \n",
    "\n",
    "        y_pre_h = np.array([])\n",
    "        y_pre_e = np.array([])\n",
    "\n",
    "        db_test_x=tf.data.Dataset.from_tensor_slices(db_test_x)\n",
    "    \n",
    "        for elem in db_test_x.as_numpy_iterator():\n",
    "            elem=tf.reshape(  elem, [1,500,4])\n",
    "\n",
    "            batch_y_pre_h,batch_y_pre_e=self.student(elem,training=False)\n",
    "            batch_y_pre_h=tf.nn.softmax(batch_y_pre_h,axis=-1)\n",
    "            batch_y_pre_e=tf.nn.softmax(batch_y_pre_e,axis=-1)\n",
    "            batch_y_pre_h=np.argmax(batch_y_pre_h,axis=-1)\n",
    "            batch_y_pre_e=np.argmax(batch_y_pre_e,axis=-1)      \n",
    "            y_pre_h = np.insert(y_pre_h, len(y_pre_h), batch_y_pre_h)\n",
    "            y_pre_e = np.insert(y_pre_e, len(y_pre_e), batch_y_pre_e)\n",
    "\n",
    "        if verbose:\n",
    "            for pre_h,pre_e in zip(y_pre_h,y_pre_e):\n",
    "                print(f\" hand prediction{pre_h}---->elbow prediction{pre_e}\")\n",
    "        return y_pre_h,y_pre_e\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b68a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "# Create the teacher\n",
    "batch_size = 128       # Batch size\n",
    "seq_len = 500     \n",
    "#learning_rate = 0.0001\n",
    "epochs = 200\n",
    "n_channels = 4\n",
    "n_class = 2\n",
    "\n",
    "\n",
    "inputs_1 = keras.layers.Input((seq_len, n_channels))\n",
    "conv_1=keras.layers.Conv1D(filters= 18, kernel_size=2, padding='Same', activation='relu', kernel_regularizer=l2(1e-3))(inputs_1)\n",
    "norm_1=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_1)\n",
    "max_1=keras.layers.MaxPool1D(pool_size=2)(norm_1)\n",
    "\n",
    "conv_2=keras.layers.Conv1D(filters= 36, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_1)\n",
    "norm_2=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_2)\n",
    "max_2=keras.layers.MaxPool1D(pool_size=2)(norm_2)\n",
    "\n",
    "conv_3=keras.layers.Conv1D(filters= 72, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_2)\n",
    "conv_3_1=keras.layers.Conv1D(filters= 72, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(conv_3)\n",
    "norm_3=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_3_1)\n",
    "max_3=keras.layers.MaxPool1D(pool_size=2)(norm_3)\n",
    "\n",
    "conv_4=keras.layers.Conv1D(filters= 144, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_3)\n",
    "conv_4_1=keras.layers.Conv1D(filters= 144, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(conv_4)\n",
    "norm_4=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_4_1)\n",
    "max_4=keras.layers.MaxPool1D(pool_size=2)(norm_4)\n",
    "flatten_1=keras.layers.Flatten()(max_4)\n",
    "\n",
    "fc_1=keras.layers.Dense(144,kernel_regularizer=l2(1e-3))(flatten_1)\n",
    "\n",
    "output_1=keras.layers.Dense(3,activation=None)(fc_1)\n",
    "output_2=keras.layers.Dense(3,activation=None)(fc_1)\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PATH =  r'./model_teacher_S.h5'    \n",
    "\n",
    "# load the teacher without softmax\n",
    "teacher_model=load_model(MODEL_PATH)\n",
    "teacher_weights = teacher_model.get_weights()\n",
    "teacher= keras.Model(inputs=inputs_1, outputs=[output_1,output_2])\n",
    "teacher.set_weights(teacher_weights)\n",
    "teacher.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the student\n",
    "inputs_1_s = keras.layers.Input((seq_len, n_channels))\n",
    "conv_1_s=keras.layers.Conv1D(filters= 18, kernel_size=2, padding='Same', activation='relu', kernel_regularizer=l2(1e-3))(inputs_1_s)\n",
    "norm_1_s=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_1_s)\n",
    "max_1_s=keras.layers.MaxPool1D(pool_size=2)(norm_1_s)\n",
    "\n",
    "conv_2_s=keras.layers.Conv1D(filters= 36, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_1_s)\n",
    "norm_2_s=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_2_s)\n",
    "max_2_s=keras.layers.MaxPool1D(pool_size=2)(norm_2_s)\n",
    "\n",
    "conv_3_s=keras.layers.Conv1D(filters= 72, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_2_s)\n",
    "conv_3_1_s=keras.layers.Conv1D(filters= 72, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(conv_3_s)\n",
    "norm_3_s=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_3_1_s)\n",
    "max_3_s=keras.layers.MaxPool1D(pool_size=2)(norm_3_s)\n",
    "\n",
    "conv_4_s=keras.layers.Conv1D(filters= 144, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(max_3_s)\n",
    "conv_4_1_s=keras.layers.Conv1D(filters= 144, kernel_size=2, padding='Same', activation='relu',kernel_regularizer=l2(1e-3))(conv_4_s)\n",
    "norm_4_s=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(conv_4_1_s)\n",
    "max_4_s=keras.layers.MaxPool1D(pool_size=2)(norm_4_s)\n",
    "flatten_1_s=keras.layers.Flatten()(max_4_s)\n",
    "\n",
    "fc_1_s=keras.layers.Dense(144,kernel_regularizer=l2(1e-3))(flatten_1_s)\n",
    "\n",
    "output_1_s=keras.layers.Dense(3,activation=None)(fc_1_s)\n",
    "output_2_s=keras.layers.Dense(3,activation=None)(fc_1_s)\n",
    "\n",
    "\n",
    "student = keras.Model(inputs=inputs_1_s, outputs=[output_1_s,output_2_s])\n",
    "\n",
    "student.set_weights(teacher_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utilities import *\n",
    "\n",
    "#############################target sata\n",
    "\n",
    "\n",
    "X_target1, labels_target_h1,labels_target_e1 = read_data(data_path='./data_wok/data_wok_train.txt', split=\"train\") # train\n",
    "X_target2, labels_target_h2,labels_target_e2 = read_data(data_path='./data_hand_and_elbow/elbow_hand_open_train.txt', split=\"train\") \n",
    "\n",
    "\n",
    "\n",
    "X_target=np.concatenate((X_target1,X_target2))\n",
    "\n",
    "\n",
    "labels_target_h=np.concatenate((labels_target_h1,labels_target_h2))\n",
    "\n",
    "\n",
    "labels_target_e=np.concatenate((labels_target_e1,labels_target_e2))\n",
    "\n",
    "\n",
    "\n",
    "labels_target_h=labels_target_h.reshape(len(labels_target_h),)\n",
    "labels_target_e=labels_target_e.reshape(len(labels_target_e),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# import matplotlib.pyplot as plt\n",
    "#import matplotlib.pyplot as plt\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import confusion_matrix     \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "#  keras\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical         #to one-hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Dense\n",
    "from keras import Input, Model\n",
    "from keras.layers import Dense, Concatenate\n",
    "from keras.regularizers import l2\n",
    "#keras.backend.set_epsilon(1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"    \n",
    "config = ConfigProto()\n",
    "config.allow_soft_placement=True \n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7  \n",
    "config.gpu_options.allow_growth = True  \n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer='adam',\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(),],\n",
    "\n",
    "    student_loss_fn= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    temperature_h=2,\n",
    "    temperature_e=0.3,\n",
    "    alpha_h=0.4, \n",
    "    alpha_e=0.4,\n",
    "\n",
    ")\n",
    "\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(os.path.join(FLAGS.checkpoint_dir, 'model_{epoch:03d}'),\n",
    "                                   verbose=1, save_weights_only=True, period=5)\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(X_target, [labels_target_h, labels_target_e], callbacks=[checkpointer],epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78256d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47c946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-keras-gpu",
   "language": "python",
   "name": "tensorflow-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
